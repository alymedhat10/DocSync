{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c3_K0GGSTrhd"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtXnXhF8U-8R"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Before get started with the Vertex AI services, we need to setup the following.\n",
    "\n",
    "* Install Python SDK\n",
    "* Environment variables\n",
    "* Authentication (Colab only)\n",
    "* Enable APIs\n",
    "* Set IAM permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjnvWl6FLUlF"
   },
   "source": [
    "### Install Python SDK\n",
    "\n",
    "Vertex AI, Cloud Storage and BigQuery APIs can be accessed with multiple ways including REST API and Python SDK. In this tutorial we will use the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FZgLGALt_al7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.59.0)\n",
      "Requirement already satisfied: google-cloud-storage in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.17.0)\n",
      "Requirement already satisfied: google-cloud-bigquery[pandas] in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.25.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (2.32.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (4.23.4)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (23.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (1.12.4)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: docstring-parser<1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-storage) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-bigquery[pandas]) (2.8.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-bigquery[pandas]) (2.0.3)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-bigquery[pandas]) (16.1.0)\n",
      "Requirement already satisfied: db-dtypes<2.0.0dev,>=0.3.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-bigquery[pandas]) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from db-dtypes<2.0.0dev,>=0.3.0->google-cloud-bigquery[pandas]) (1.24.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.0->google-cloud-bigquery[pandas]) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.0->google-cloud-bigquery[pandas]) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery[pandas]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.5.7)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\DELL\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --user google-cloud-aiplatform google-cloud-storage google-cloud-bigquery[pandas] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRvKdaPDTznN",
    "outputId": "154a71b5-f302-4f53-ed2f-b3e5fef9195b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCoTvkOJoh76"
   },
   "source": [
    "### Environment variables (Start Running from here)\n",
    "\n",
    "Sets environment variables. If asked, please replace the following `[your-project-id]` with your project ID and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fkmvFRrj3nQI"
   },
   "outputs": [],
   "source": [
    "# get project ID\n",
    "#PROJECT_ID = ! gcloud config get project\n",
    "#PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\"\n",
    "#if PROJECT_ID == \"(unset)\":\n",
    "#    print(f\"Please set the project ID manually below\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define project information\n",
    "#if PROJECT_ID == \"(unset)\":\n",
    "#    PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# generate an unique id for this session\n",
    "from datetime import datetime\n",
    "\n",
    "UID = datetime.now().strftime(\"%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "69XJ95rNoYG9"
   },
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_ID = 'tokyo-country-189103'  \n",
    "#bq_client = bigquery.Client(project=PROJECT_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ph7mDSMRVTIZ"
   },
   "source": [
    "### Authentication (Colab only)\n",
    "\n",
    "If you are running this notebook on Colab, you will need to run the following cell authentication. This step is not required if you are using Vertex AI Workbench as it is pre-authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5jQkFtlimNXR"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# if it's Colab runtime, authenticate the user with Google Cloud\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] += os.pathsep + r'C:\\Users\\DELL\\AppData\\Local\\Google\\Cloud SDK\\google-cloud-sdk\\bin'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUPbl4IFLmC2"
   },
   "source": [
    "### Enable APIs\n",
    "\n",
    "Run the following to enable APIs for Compute Engine, Vertex AI, Cloud Storage and BigQuery with this Google Cloud project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qGf0qMMQNond"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operation \"operations/acat.p2-303276163211-6d598cbd-fcbb-4cb0-a090-13c29ede3293\" finished successfully.\n"
     ]
    }
   ],
   "source": [
    "! gcloud services enable compute.googleapis.com aiplatform.googleapis.com storage.googleapis.com bigquery.googleapis.com --project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mahCxLXHMIls"
   },
   "source": [
    "## Getting Started with Vertex AI Embeddings for Text\n",
    "\n",
    "Now it's ready to get started with embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rq07_-o0VoZD"
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "We will be using [the Stack Overflow public dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) hosted on BigQuery table `bigquery-public-data.stackoverflow.posts_questions`. This is a very big dataset with 23 million rows that doesn't fit into the memory. We are going to limit it to 1000 rows for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "# Set environment variable for your service account key\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r\"C:\\Users\\DELL\\Python projects\\DocSync\\V2\\Key\\tokyo-country-189103-4ce23189dd39.json\"  # Replace with your actual path\n",
    "\n",
    "# Initialize BigQuery client\n",
    "bq_client = bigquery.Client(project=PROJECT_ID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "snrzPsEQDH4S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73422998</td>\n",
       "      <td>merge rows based on a specific date interval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73462590</td>\n",
       "      <td>why real-time DEVS are always in sync in DEVS/SOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73463551</td>\n",
       "      <td>Modernizing and simplifying an old node.js+mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73485120</td>\n",
       "      <td>Print arabic characters using logstash exec pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73341249</td>\n",
       "      <td>Auditing packages brings back more errors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title\n",
       "0  73422998       merge rows based on a specific date interval\n",
       "1  73462590  why real-time DEVS are always in sync in DEVS/SOA\n",
       "2  73463551  Modernizing and simplifying an old node.js+mon...\n",
       "3  73485120  Print arabic characters using logstash exec pl...\n",
       "4  73341249          Auditing packages brings back more errors"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the BQ Table into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "QUESTIONS_SIZE = 1000\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "QUERY_TEMPLATE = \"\"\"\n",
    "        SELECT distinct q.id, q.title\n",
    "        FROM (SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "        where Score > 0 ORDER BY View_Count desc) AS q\n",
    "        LIMIT {limit} ;\n",
    "        \"\"\"\n",
    "query = QUERY_TEMPLATE.format(limit=QUESTIONS_SIZE)\n",
    "query_job = bq_client.query(query)\n",
    "rows = query_job.result()\n",
    "df = rows.to_dataframe()\n",
    "\n",
    "# examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing the Two excl FIle that will be compared together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Requirement ID</th>\n",
       "      <th>Requirement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_NEW_1</td>\n",
       "      <td>The sun set behind the towering mountains, cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_NEW_2</td>\n",
       "      <td>She smiled warmly as she received the unexpect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_NEW_3</td>\n",
       "      <td>The cat purred contentedly on the windowsill, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_NEW_4</td>\n",
       "      <td>Rain tapped gently against the roof, creating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_NEW_5</td>\n",
       "      <td>He finished the marathon with a triumphant che...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Requirement ID                                        Requirement\n",
       "0       ID_NEW_1  The sun set behind the towering mountains, cas...\n",
       "1       ID_NEW_2  She smiled warmly as she received the unexpect...\n",
       "2       ID_NEW_3  The cat purred contentedly on the windowsill, ...\n",
       "3       ID_NEW_4  Rain tapped gently against the roof, creating ...\n",
       "4       ID_NEW_5  He finished the marathon with a triumphant che..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_excel(r'C:\\Users\\DELL\\Python projects\\DocSync\\V2\\DocSync\\SamplesForTesting\\New_Doc.xlsx')\n",
    "old_df = pd.read_excel(r'C:\\Users\\DELL\\Python projects\\DocSync\\V2\\DocSync\\SamplesForTesting\\Old_Doc.xlsx')\n",
    "\n",
    "new_df['Requirement'] = new_df['Requirement'].astype(str)\n",
    "old_df['Requirement'] = old_df['Requirement'].astype(str)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6022U1FWzpb"
   },
   "source": [
    "### Call the API to generate embeddings\n",
    "\n",
    "With the Stack Overflow dataset, we will use the `title` column (the question title) and generate embedding for it with Embeddings for Text API. The API is available under the [vertexai](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai) package of the SDK.\n",
    "\n",
    "You may see some warning messages from the TensorFlow library but you can ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pY8M4DqO8wGx"
   },
   "outputs": [],
   "source": [
    "# init the vertexai package\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrG82n-y-EC5"
   },
   "source": [
    "From the package, import [TextEmbeddingModel](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.TextEmbeddingModel) and get a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YVLHjSeOGoTu"
   },
   "outputs": [],
   "source": [
    "# Load the text embeddings model\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqdVsgZDb_hc"
   },
   "source": [
    "In this tutorial we will use `textembedding-gecko@001` model for getting text embeddings. Please take a look at [Supported models](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings#supported_models) on the doc to see the list of supported models.\n",
    "\n",
    "Once you get the model, you can call its [get_embeddings](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models.TextEmbeddingModel#vertexai_language_models_TextEmbeddingModel_get_embeddings) function to get embeddings. You can pass up to 5 texts at once in a call. But there is a caveat. By default, the text embeddings API has a \"request per minute\" quota set to 60 for new Cloud projects and 600 for projects with usage history (see [Quotas and limits](https://cloud.google.com/vertex-ai/docs/quotas#request_quotas) to check the latest quota value for `base_model:textembedding-gecko`). So, rather than using the function directly, you may want to define a wrapper like below to limit under 10 calls per second, and pass 5 texts each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8HUb9u_P2VWW"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm  # to show a progress bar\n",
    "\n",
    "# get embeddings for a list of texts\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "\n",
    "def get_embeddings_wrapper(texts):\n",
    "    embs = []\n",
    "    for i in tqdm.tqdm(range(0, len(texts), BATCH_SIZE)):\n",
    "        time.sleep(1)  # to avoid the quota error\n",
    "        result = model.get_embeddings(texts[i : i + BATCH_SIZE])\n",
    "        embs = embs + [e.values for e in result]\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aK4eTSPfcEuh"
   },
   "source": [
    "The following code will get embedding for the question titles and add them as a new column `embedding` to the DataFrame. This will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FcqPvu4PluN1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:34<00:00,  1.71s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Requirement ID</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_NEW_1</td>\n",
       "      <td>The sun set behind the towering mountains, cas...</td>\n",
       "      <td>[-0.06087258830666542, 0.02693977579474449, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_NEW_2</td>\n",
       "      <td>She smiled warmly as she received the unexpect...</td>\n",
       "      <td>[0.021243004128336906, 0.052161142230033875, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_NEW_3</td>\n",
       "      <td>The cat purred contentedly on the windowsill, ...</td>\n",
       "      <td>[0.007877746596932411, 0.0007245641900226474, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_NEW_4</td>\n",
       "      <td>Rain tapped gently against the roof, creating ...</td>\n",
       "      <td>[-0.02790035679936409, 0.008891325443983078, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_NEW_5</td>\n",
       "      <td>He finished the marathon with a triumphant che...</td>\n",
       "      <td>[-0.0031797306146472692, 0.003588359570130706,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Requirement ID                                        Requirement  \\\n",
       "0       ID_NEW_1  The sun set behind the towering mountains, cas...   \n",
       "1       ID_NEW_2  She smiled warmly as she received the unexpect...   \n",
       "2       ID_NEW_3  The cat purred contentedly on the windowsill, ...   \n",
       "3       ID_NEW_4  Rain tapped gently against the roof, creating ...   \n",
       "4       ID_NEW_5  He finished the marathon with a triumphant che...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.06087258830666542, 0.02693977579474449, -0...  \n",
       "1  [0.021243004128336906, 0.052161142230033875, -...  \n",
       "2  [0.007877746596932411, 0.0007245641900226474, ...  \n",
       "3  [-0.02790035679936409, 0.008891325443983078, 9...  \n",
       "4  [-0.0031797306146472692, 0.003588359570130706,...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get embeddings for the question titles and add them as \"embedding\" column\n",
    "new_df = new_df.assign(embedding=get_embeddings_wrapper(list(new_df.Requirement)))\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:32<00:00,  1.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Requirement ID</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_OLD_1</td>\n",
       "      <td>She found solace watching the sunset from her ...</td>\n",
       "      <td>[-0.056000467389822006, -0.023922106251120567,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_OLD_2</td>\n",
       "      <td>The background was filled with the steady tick...</td>\n",
       "      <td>[-0.008554883301258087, 0.012233082205057144, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_OLD_3</td>\n",
       "      <td>The kitchen was enveloped in the enticing arom...</td>\n",
       "      <td>[-0.03560804948210716, 0.019117780029773712, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_OLD_4</td>\n",
       "      <td>The room was quiet, save for the gentle hum of...</td>\n",
       "      <td>[0.02677360363304615, -0.014026092365384102, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_OLD_5</td>\n",
       "      <td>By the river's edge, the old man quietly fishe...</td>\n",
       "      <td>[0.023639937862753868, 0.0027894822414964437, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Requirement ID                                        Requirement  \\\n",
       "0       ID_OLD_1  She found solace watching the sunset from her ...   \n",
       "1       ID_OLD_2  The background was filled with the steady tick...   \n",
       "2       ID_OLD_3  The kitchen was enveloped in the enticing arom...   \n",
       "3       ID_OLD_4  The room was quiet, save for the gentle hum of...   \n",
       "4       ID_OLD_5  By the river's edge, the old man quietly fishe...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.056000467389822006, -0.023922106251120567,...  \n",
       "1  [-0.008554883301258087, 0.012233082205057144, ...  \n",
       "2  [-0.03560804948210716, 0.019117780029773712, 0...  \n",
       "3  [0.02677360363304615, -0.014026092365384102, 0...  \n",
       "4  [0.023639937862753868, 0.0027894822414964437, ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get embeddings for the question titles and add them as \"embedding\" column\n",
    "old_df = old_df.assign(embedding=get_embeddings_wrapper(list(old_df.Requirement)))\n",
    "old_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB53SiJjVN6e"
   },
   "source": [
    "## Look at the embedding similarities\n",
    "\n",
    "Let's see how these embeddings are organized in the embedding space with their meanings by quickly calculating the similarities between them and sorting them.\n",
    "\n",
    "As embeddings are vectors, you can calculate similarity between two embeddings by using one of the popular metrics like the followings:\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/8.png)\n",
    "\n",
    "Which metric should we use? Usually it depends on how each model is trained. In case of the model `textembedding-gecko@001`, we need to use inner product (dot product).\n",
    "\n",
    "In the following code, it picks up one question randomly and uses the numpy `np.dot` function to calculate the similarities between the question and other questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the embeddings to numpy arrays for similarity calculation\n",
    "new_embeddings = np.array(new_df['embedding'].tolist())\n",
    "old_embeddings = np.array(old_df['embedding'].tolist())\n",
    "\n",
    "# Calculate the similarity matrix using dot product\n",
    "similarity_matrix = np.dot(new_embeddings, old_embeddings.T)\n",
    "\n",
    "# Find the most similar requirement in the old excel for each requirement in the new excel\n",
    "most_similar_indices = np.argmax(similarity_matrix, axis=1)\n",
    "most_similar_scores = np.max(similarity_matrix, axis=1)\n",
    "\n",
    "# Create the comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'new_requirement_id': new_df['Requirement ID'],\n",
    "    'new_requirement_text': new_df['Requirement'],\n",
    "    'most_similar_requirement_text': old_df['Requirement'].iloc[most_similar_indices].values,\n",
    "    'most_similar_requirement_id': old_df['Requirement ID'].iloc[most_similar_indices].values,\n",
    "    'matching_percentage': most_similar_scores\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_requirement_id</th>\n",
       "      <th>new_requirement_text</th>\n",
       "      <th>most_similar_requirement_text</th>\n",
       "      <th>most_similar_requirement_id</th>\n",
       "      <th>matching_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_NEW_1</td>\n",
       "      <td>The sun set behind the towering mountains, cas...</td>\n",
       "      <td>The sun cast a golden glow over the valley, pa...</td>\n",
       "      <td>ID_OLD_37</td>\n",
       "      <td>0.859175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_NEW_2</td>\n",
       "      <td>She smiled warmly as she received the unexpect...</td>\n",
       "      <td>Unexpectedly, she received a gift from her dea...</td>\n",
       "      <td>ID_OLD_90</td>\n",
       "      <td>0.963568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_NEW_3</td>\n",
       "      <td>The cat purred contentedly on the windowsill, ...</td>\n",
       "      <td>The contented cat purred softly on the windows...</td>\n",
       "      <td>ID_OLD_36</td>\n",
       "      <td>0.962184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_NEW_4</td>\n",
       "      <td>Rain tapped gently against the roof, creating ...</td>\n",
       "      <td>Raindrops provided a soothing rhythm on the roof.</td>\n",
       "      <td>ID_OLD_46</td>\n",
       "      <td>0.884464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_NEW_5</td>\n",
       "      <td>He finished the marathon with a triumphant che...</td>\n",
       "      <td>Crisp fall mornings invigorated him.</td>\n",
       "      <td>ID_OLD_95</td>\n",
       "      <td>0.630703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ID_NEW_96</td>\n",
       "      <td>The aroma of fresh herbs filled the kitchen.</td>\n",
       "      <td>The kitchen was infused with the aromatic scen...</td>\n",
       "      <td>ID_OLD_38</td>\n",
       "      <td>0.965957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ID_NEW_97</td>\n",
       "      <td>She enjoyed the cool breeze on a summer evening.</td>\n",
       "      <td>She found solace watching the sunset from her ...</td>\n",
       "      <td>ID_OLD_1</td>\n",
       "      <td>0.711254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ID_NEW_98</td>\n",
       "      <td>The sound of waves crashing was a constant rem...</td>\n",
       "      <td>Waves crashing reminded him of the sea's power.</td>\n",
       "      <td>ID_OLD_49</td>\n",
       "      <td>0.889294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ID_NEW_99</td>\n",
       "      <td>He loved the crispness of a fall afternoon.</td>\n",
       "      <td>Crisp fall mornings invigorated him.</td>\n",
       "      <td>ID_OLD_95</td>\n",
       "      <td>0.835081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ID_NEW_100</td>\n",
       "      <td>The gentle hum of bees was a sign of summer.</td>\n",
       "      <td>Bees hummed softly, announcing the arrival of ...</td>\n",
       "      <td>ID_OLD_44</td>\n",
       "      <td>0.914894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_requirement_id                               new_requirement_text  \\\n",
       "0            ID_NEW_1  The sun set behind the towering mountains, cas...   \n",
       "1            ID_NEW_2  She smiled warmly as she received the unexpect...   \n",
       "2            ID_NEW_3  The cat purred contentedly on the windowsill, ...   \n",
       "3            ID_NEW_4  Rain tapped gently against the roof, creating ...   \n",
       "4            ID_NEW_5  He finished the marathon with a triumphant che...   \n",
       "..                ...                                                ...   \n",
       "95          ID_NEW_96       The aroma of fresh herbs filled the kitchen.   \n",
       "96          ID_NEW_97   She enjoyed the cool breeze on a summer evening.   \n",
       "97          ID_NEW_98  The sound of waves crashing was a constant rem...   \n",
       "98          ID_NEW_99        He loved the crispness of a fall afternoon.   \n",
       "99         ID_NEW_100       The gentle hum of bees was a sign of summer.   \n",
       "\n",
       "                        most_similar_requirement_text  \\\n",
       "0   The sun cast a golden glow over the valley, pa...   \n",
       "1   Unexpectedly, she received a gift from her dea...   \n",
       "2   The contented cat purred softly on the windows...   \n",
       "3   Raindrops provided a soothing rhythm on the roof.   \n",
       "4                Crisp fall mornings invigorated him.   \n",
       "..                                                ...   \n",
       "95  The kitchen was infused with the aromatic scen...   \n",
       "96  She found solace watching the sunset from her ...   \n",
       "97    Waves crashing reminded him of the sea's power.   \n",
       "98               Crisp fall mornings invigorated him.   \n",
       "99  Bees hummed softly, announcing the arrival of ...   \n",
       "\n",
       "   most_similar_requirement_id  matching_percentage  \n",
       "0                    ID_OLD_37             0.859175  \n",
       "1                    ID_OLD_90             0.963568  \n",
       "2                    ID_OLD_36             0.962184  \n",
       "3                    ID_OLD_46             0.884464  \n",
       "4                    ID_OLD_95             0.630703  \n",
       "..                         ...                  ...  \n",
       "95                   ID_OLD_38             0.965957  \n",
       "96                    ID_OLD_1             0.711254  \n",
       "97                   ID_OLD_49             0.889294  \n",
       "98                   ID_OLD_95             0.835081  \n",
       "99                   ID_OLD_44             0.914894  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lKs6jSu7NiM6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.526026  , 0.55304776, 0.45136549, 0.56357067, 0.4500969 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# pick one of them as a key question\n",
    "key = random.randint(0, len(new_df))\n",
    "\n",
    "# calc dot product between the key and other questions\n",
    "embs = np.array(new_df.embedding.to_list())\n",
    "similarities = np.dot(embs[key], embs.T)\n",
    "\n",
    "# print similarities for the first 5 questions\n",
    "similarities[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srM04lJBQp4w"
   },
   "source": [
    "Finally, sort the questions with the similarities and print the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lTUVvj9FQlab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key question: She felt the soft sand beneath her feet at the shore.\n",
      "\n",
      "1.0000 She felt the soft sand beneath her feet at the shore.\n",
      "0.7720 The warm sand felt good under his feet.\n",
      "0.6990 She enjoyed the peacefulness of the empty beach.\n",
      "0.6975 She enjoyed a peaceful walk along the beach at dusk.\n",
      "0.6560 He felt a sense of peace standing by the ocean.\n",
      "0.6384 She enjoyed the sweet taste of the ripe fruit.\n",
      "0.6374 She loved the smell of freshly cut grass in the summer.\n",
      "0.6316 She found joy in the simplicity of a morning walk.\n",
      "0.6293 She found comfort in the familiar scent of home.\n",
      "0.6291 Waves crashed rhythmically on the shore, echoing the heartbeat of the ocean, and creating a mesmerizing, eternal dance.\n",
      "0.6282 The sound of waves crashing was a constant reminder of the sea.\n",
      "0.6268 The gentle lapping of the lake was peaceful.\n",
      "0.6246 She enjoyed the cool breeze on a summer evening.\n",
      "0.6232 She appreciated the beauty of a starry night.\n",
      "0.6216 The sound of waves lapping against the boat was soothing.\n",
      "0.6086 The gentle sound of the river was calming.\n",
      "0.6083 She marveled at the beauty of the snow-covered landscape.\n",
      "0.6059 The fresh scent of the ocean breeze was invigorating.\n",
      "0.6017 She wrapped herself in a cozy blanket, savoring the warmth.\n",
      "0.5853 She felt a sense of nostalgia walking through the old neighborhood.\n"
     ]
    }
   ],
   "source": [
    "# print the question\n",
    "print(f\"Key question: {new_df.Requirement[key]}\\n\")\n",
    "\n",
    "# sort and print the questions by similarities\n",
    "sorted_questions = sorted(\n",
    "    zip(new_df.Requirement, similarities), key=lambda x: x[1], reverse=True\n",
    ")[:20]\n",
    "for i, (question, similarity) in enumerate(sorted_questions):\n",
    "    print(f\"{similarity:.4f} {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S75SQzAg1wHV"
   },
   "source": [
    "# Find embeddings fast with Vertex AI Vector Search\n",
    "\n",
    "As we have explained above, you can find similar embeddings by calculating the distance or similarity between the embeddings.\n",
    "\n",
    "But this isn't easy when you have millions or billions of embeddings. For example, if you have 1 million embeddings with 768 dimensions, you need to repeat the distance calculations for 1 million x 768 times. This would take some seconds - too slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sjhTy-a47YH"
   },
   "source": [
    "So the researchers have been studying a technique called [Approximate Nearest Neighbor (ANN)](https://en.wikipedia.org/wiki/Nearest_neighbor_search) for faster search. ANN uses \"vector quantization\" for separating the space into multiple spaces with a tree structure. This is similar to the index in relational databases for improving the query performance, enabling very fast and scalable search with billions of embeddings.\n",
    "\n",
    "With the rise of LLMs, the ANN is getting popular quite rapidly, known as the Vector Search technology.\n",
    "\n",
    "![](https://storage.googleapis.com/gweb-cloudblog-publish/images/7._ANN.1143068821171228.max-2200x2200.png)\n",
    "\n",
    "In 2020, Google Research published a new ANN algorithm called [ScaNN](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html). It is considered one of the best ANN algorithms in the industry, also the most important foundation for search and recommendation in major Google services such as Google Search, YouTube and many others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVOL8BgM2isz"
   },
   "source": [
    "## What is Vertex AI Vector Search?\n",
    "\n",
    "Google Cloud developers can take the full advantage of Google's vector search technology with [Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview) (previously called Matching Engine). With this fully managed service, developers can just add the embeddings to its index and issue a search query with a key embedding for the blazingly fast vector search. In the case of the Stack Overflow demo, Vector Search can find relevant questions from 8 million embeddings in tens of milliseconds.\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/textemb-vs-notebook/9.png)\n",
    "\n",
    "With Vector Search, you don't need to spend much time and money building your own vector search service from scratch or using open source tools if your goal is high scalability, availability and maintainability for production systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBt8tjidSzyU"
   },
   "source": [
    "## Get Started with Vector Search\n",
    "\n",
    "When you already have the embeddings, then getting started with Vector Search is pretty easy. In this section, we will follow the steps below.\n",
    "\n",
    "### Setting up Vector Search\n",
    "- Save the embeddings in JSON files on Cloud Storage\n",
    "- Build an Index\n",
    "- Create an Index Endpoint\n",
    "- Deploy the Index to the endpoint\n",
    "\n",
    "### Use Vector Search\n",
    "\n",
    "- Query with the endpoint\n",
    "\n",
    "### **Tip for Colab users**\n",
    "\n",
    "If you use Colab for this tutorial, you may lose your runtime while you are waiting for the Index building and deployment in the later sections as it takes tens of minutes. In that case, run the following sections again with the new instance to recover the runtime: [Install Python SDK, Environment variables and Authentication](https://colab.research.google.com/drive/1xJhLFEyPqW0qvKiERD6aYgeTHa6_U50N?resourcekey=0-2qUkxckCjt6W03AsqvZHhw#scrollTo=AtXnXhF8U-8R&line=9&uniqifier=1).\n",
    "\n",
    "Then, use the [Utilities](https://colab.research.google.com/drive/1xJhLFEyPqW0qvKiERD6aYgeTHa6_U50N?resourcekey=0-2qUkxckCjt6W03AsqvZHhw#scrollTo=BE1tELsH-u8N&line=1&uniqifier=1) to recover the Index and Index Endpoint and continute with the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pu1a3zjfQ0D"
   },
   "source": [
    "### Save the embeddings in a JSON file\n",
    "To load the embeddings to Vector Search, we need to save them in JSON files with JSONL format. See more information in the docs at [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup/format-structure#data-file-formats).\n",
    "\n",
    "First, export the `id` and `embedding` columns from the DataFrame in JSONL format, and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GzZ30d4j_uLU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# save id and embedding as a json file\n",
    "jsonl_string = new_df[[\"Requirement\", \"Requirement ID\"]].to_json(orient=\"records\", lines=True)\n",
    "with open(\"questions.json\", \"w\") as f:\n",
    "    f.write(jsonl_string)\n",
    "\n",
    "# show the first few lines of the json file\n",
    "#! head -n 3 questions.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WTNJ3FAQl_W"
   },
   "source": [
    "Then, create a new Cloud Storage bucket and copy the file to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "CzwDWJfzAk3n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBUCKET_URI = f\"gs://{PROJECT_ID}-embvs-tutorial-{UID}\"\\n! gsutil mb -l $LOCATION -p {PROJECT_ID} {BUCKET_URI}\\n! gsutil cp questions.json {BUCKET_URI}\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "BUCKET_URI = f\"gs://{PROJECT_ID}-embvs-tutorial-{UID}\"\n",
    "! gsutil mb -l $LOCATION -p {PROJECT_ID} {BUCKET_URI}\n",
    "! gsutil cp questions.json {BUCKET_URI}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxdbjKw1XDxl"
   },
   "source": [
    "### Create an Index\n",
    "\n",
    "Now it's ready to load the embeddings to Vector Search. Its APIs are available under the [aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform) package of the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8unyr9KagAoI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# init the aiplatform package\\nfrom google.cloud import aiplatform\\n\\naiplatform.init(project=PROJECT_ID, location=LOCATION)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# init the aiplatform package\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpMUXqWQ75uu"
   },
   "source": [
    "Create an [MatchingEngineIndex](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex) with its `create_tree_ah_index` function (Matching Engine is the previous name of Vector Search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "kKDw5VXMkXb3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aiplatform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create index\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m my_index \u001b[38;5;241m=\u001b[39m \u001b[43maiplatform\u001b[49m\u001b[38;5;241m.\u001b[39mMatchingEngineIndex\u001b[38;5;241m.\u001b[39mcreate_tree_ah_index(\n\u001b[0;32m      3\u001b[0m     display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membvs-tutorial-index-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mUID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     contents_delta_uri\u001b[38;5;241m=\u001b[39mBUCKET_URI,\n\u001b[0;32m      5\u001b[0m     dimensions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m768\u001b[39m,\n\u001b[0;32m      6\u001b[0m     approximate_neighbors_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m      7\u001b[0m     distance_measure_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOT_PRODUCT_DISTANCE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aiplatform' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# create index\n",
    "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=f\"embvs-tutorial-index-{UID}\",\n",
    "    contents_delta_uri=BUCKET_URI,\n",
    "    dimensions=768,\n",
    "    approximate_neighbors_count=20,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rFam_w9U0dI"
   },
   "source": [
    "By calling the `create_tree_ah_index` function, it starts building an Index. This will take under a few minutes if the dataset is small, otherwise about 50 minutes or more depending on the size of the dataset. You can check status of the index creation on [the Vector Search Console > INDEXES tab](https://console.cloud.google.com/vertex-ai/matching-engine/indexes).\n",
    "\n",
    "![](https://storage.googleapis.com/github-repo/img/embeddings/vs-quickstart/creating-index.png)\n",
    "\n",
    "#### The parameters for creating index\n",
    "\n",
    "- `contents_delta_uri`: The URI of Cloud Storage directory where you stored the embedding JSON files\n",
    "- `dimensions`: Dimension size of each embedding. In this case, it is 768 as we are using the embeddings from the Text Embeddings API.\n",
    "- `approximate_neighbors_count`: how many similar items we want to retrieve in typical cases\n",
    "- `distance_measure_type`: what metrics to measure distance/similarity between embeddings. In this case it's `DOT_PRODUCT_DISTANCE`\n",
    "\n",
    "See [the document](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index) for more details on creating Index and the parameters.\n",
    "\n",
    "#### Batch Update or Streaming Update?\n",
    "There are two types of index: Index for *Batch Update* (used in this tutorial) and Index for *Streaming Updates*. The Batch Update index can be updated with a batch process whereas the Streaming Update index can be updated in real-time. The latter one is more suited for use cases where you want to add or update each embeddings in the index more often, and crucial to serve with the latest embeddings, such as e-commerce product search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLOAMF50XMI8"
   },
   "source": [
    "### Create Index Endpoint and deploy the Index\n",
    "\n",
    "To use the Index, you need to create an [Index Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public). It works as a server instance accepting query requests for your Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6IzyufWCjU1"
   },
   "outputs": [],
   "source": [
    "# create IndexEndpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=f\"embvs-tutorial-index-endpoint-{UID}\",\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial utilizes a [Public Endpoint](https://cloud.google.com/vertex-ai/docs/vector-search/setup/setup#choose-endpoint) and does not support [Virtual Private Cloud (VPC)](https://cloud.google.com/vpc/docs/private-services-access). Unless you have a specific requirement for VPC, we recommend using a Public Endpoint. Despite the term \"public\" in its name, it does not imply open access to the public internet. Rather, it functions like other endpoints in Vertex AI services, which are secured by default through IAM. Without explicit IAM permissions, as we have previously established, no one can access the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n33iO1T5hFO"
   },
   "source": [
    "With the Index Endpoint, deploy the Index by specifying an unique deployed index ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcBHLifGwAWq"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = f\"embvs_tutorial_deployed_{UID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jUoGhY5TPFP"
   },
   "outputs": [],
   "source": [
    "# deploy the Index to the Index Endpoint\n",
    "my_index_endpoint.deploy_index(index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu9ZmWcpXQ55"
   },
   "source": [
    "If it is the first time to deploy an Index to an Index Endpoint, it will take around 25 minutes to automatically build and initiate the backend for it. After the first deployment, it will finish in seconds. To see the status of the index deployment, open [the Vector Search Console > INDEX ENDPOINTS tab](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints) and click the Index Endpoint.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/github-repo/img/embeddings/vs-quickstart/deploying-index.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTi4PjjbXV-O"
   },
   "source": [
    "### Run Query\n",
    "\n",
    "Finally it's ready to use Vector Search. In the following code, it creates an embedding for a test question, and find similar question with the Vector Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhNuRQqUWdfe"
   },
   "outputs": [],
   "source": [
    "test_embeddings = get_embeddings_wrapper([\"How to read JSON with Python?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q01DGMBPXAg-"
   },
   "outputs": [],
   "source": [
    "# Test query\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=20,\n",
    ")\n",
    "\n",
    "# show the result\n",
    "import numpy as np\n",
    "\n",
    "for idx, neighbor in enumerate(response[0]):\n",
    "    id = np.int64(neighbor.id)\n",
    "    similar = df.query(\"id == @id\", engine=\"python\")\n",
    "    print(f\"{neighbor.distance:.4f} {similar.title.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPDOL9caoYZ9"
   },
   "source": [
    "The `find_neighbors` function only takes milliseconds to fetch the similar items even when you have billions of items on the Index, thanks to the ScaNN algorithm. Vector Search also supports [autoscaling](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public#autoscaling) which can automatically resize the number of nodes based on the demands of your workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDt4D6FDyc66"
   },
   "source": [
    "# IMPORTANT: Cleaning Up\n",
    "\n",
    "In case you are using your own Cloud project, not a temporary project on Qwiklab, please make sure to delete all the Indexes, Index Endpoints and Cloud Storage buckets after finishing this tutorial. Otherwise the remaining objects would **incur unexpected costs**.\n",
    "\n",
    "If you used Workbench, you may also need to delete the Notebooks from [the console](https://console.cloud.google.com/vertex-ai/workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEsKVzguyxNx"
   },
   "outputs": [],
   "source": [
    "# wait for a confirmation\n",
    "input(\"Press Enter to delete Index Endpoint, Index and Cloud Storage bucket:\")\n",
    "\n",
    "# delete Index Endpoint\n",
    "my_index_endpoint.undeploy_all()\n",
    "my_index_endpoint.delete(force=True)\n",
    "\n",
    "# delete Index\n",
    "my_index.delete()\n",
    "\n",
    "# delete Cloud Storage bucket\n",
    "! gsutil rm -r {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8k26QOF3Ys7"
   },
   "source": [
    "# Summary\n",
    "\n",
    "## Grounding LLM outputs with Vertex AI Vector Search\n",
    "\n",
    "As we have seen, by combining the Embeddings API and Vector Search, you can use the embeddings to \"ground\" LLM outputs to real business data with low latency.\n",
    "\n",
    "For example, if an user asks a question, Embeddings API can convert it to an embedding, and issue a query on Vector Search to find similar embeddings in its index. Those embeddings represent the actual business data in the databases. As we are just retrieving the business data and not generating any artificial texts, there is no risk of having hallucinations in the result.\n",
    "\n",
    "![](https://storage.googleapis.com/gweb-cloudblog-publish/original_images/10._grounding.png)\n",
    "\n",
    "### The difference between the questions and answers\n",
    "\n",
    "In this tutorial, we have used the Stack Overflow dataset. There is a reason why we had to use it; As the dataset has many pairs of **questions and answers**, so you can just find questions similar to your question to find answers to it.\n",
    "\n",
    "In many business use cases, the semantics (meaning) of questions and answers are different. Also, there could be cases where you would want to add variety of recommended or personalized items to the results, like product search on e-commerce sites.\n",
    "\n",
    "In these cases, the simple semantics search don't work well. It's more like a recommendation system problem where you may want to train a model (e.g. Two-Tower model) to learn the relationship between the question embedding space and answer embedding space. Also, many production systems adds reranking phase after the semantic search to achieve higher search quality. Please see [Scaling deep retrieval with TensorFlow Recommenders and Vertex AI Matching Engine](https://cloud.google.com/blog/products/ai-machine-learning/scaling-deep-retrieval-tensorflow-two-towers-architecture) to learn more.\n",
    "\n",
    "### Hybrid of semantic + keyword search\n",
    "\n",
    "Another typical challenge you will face in production system is to support keyword search combined with the semantic search. For example, for e-commerce product search, you may want to let users find product by entering its product name or model number. As LLM doesn't memorize those product names or model numbers, semantic search can't handle those \"usual\" search functionalities.\n",
    "\n",
    "[Vertex AI Search](https://cloud.google.com/blog/products/ai-machine-learning/vertex-ai-search-and-conversation-is-now-generally-available) is another product you may consider for those requirements. While Vector Search provides a simple semantic search capability only, Search provides a integrated search solution that combines semantic search, keyword search, reranking and filtering, available as an out-of-the-box tool.\n",
    "\n",
    "### What about Retrieval Augmented Generation (RAG)?\n",
    "\n",
    "In this tutorial, we have looked at the simple combination of LLM embeddings and vector search. From this starting point, you may also extend the design to [Retrieval Augmented Generation (RAG)](https://www.google.com/search?q=Retrieval+Augmented+Generation+(RAG)&oq=Retrieval+Augmented+Generation+(RAG)).\n",
    "\n",
    "RAG is a popular architecture pattern of implementing grounding with LLM with text chat UI. The idea is to have the LLM text chat UI as a frontend for the document retrieval with vector search and summarization of the result.\n",
    "\n",
    "![](https://storage.googleapis.com/gweb-cloudblog-publish/images/Figure-7-Ask_Your_Documents_Flow.max-529x434.png)\n",
    "\n",
    "There are some pros and cons between the two solutions.\n",
    "\n",
    "| | Emb + vector search | RAG |\n",
    "|---|---|---|\n",
    "| Design | simple | complex |\n",
    "| UI | Text search UI | Text chat UI |\n",
    "| Summarization of result | No | Yes |\n",
    "| Multi-turn (Context aware) | No | Yes |\n",
    "| Latency | millisecs | seconds |\n",
    "| Cost | lower | higher |\n",
    "| Hallucinations | No risk | Some risk |\n",
    "\n",
    "The Embedding + vector search pattern we have looked at with this tutorial provides simple, fast and low cost semantic search functionality with the LLM intelligence. RAG adds context-aware text chat experience and result summarization to it. While RAG provides the more \"Gen AI-ish\" experience, it also adds a risk of hallucination and higher cost and time for the text generation.\n",
    "\n",
    "To learn more about how to build a RAG solution, you may look at [Building Generative AI applications made easy with Vertex AI PaLM API and LangChain](https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-applications-with-vertex-ai-palm-2-models-and-langchain).\n",
    "\n",
    "## Resources\n",
    "\n",
    "To learn more, please check out the following resources:\n",
    "\n",
    "### Documentations\n",
    "\n",
    "[Vertex AI Embeddings for Text API documentation\n",
    "](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings)\n",
    "\n",
    "[Vector Search documentation](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)\n",
    "\n",
    "### Vector Search blog posts\n",
    "\n",
    "[Vertex Matching Engine: Blazing fast and massively scalable nearest neighbor search](https://cloud.google.com/blog/products/ai-machine-learning/vertex-matching-engine-blazing-fast-and-massively-scalable-nearest-neighbor-search)\n",
    "\n",
    "[Find anything blazingly fast with Google's vector search technology](https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology)\n",
    "\n",
    "[Enabling real-time AI with Streaming Ingestion in Vertex AI](https://cloud.google.com/blog/products/ai-machine-learning/real-time-ai-with-google-cloud-vertex-ai)\n",
    "\n",
    "[Mercari leverages Google's vector search technology to create a new marketplace](https://cloud.google.com/blog/topics/developers-practitioners/mercari-leverages-googles-vector-search-technology-create-new-marketplace)\n",
    "\n",
    "[Recommending news articles using Vertex AI Matching Engine](https://cloud.google.com/blog/products/ai-machine-learning/recommending-articles-using-vertex-ai-matching-engine)\n",
    "\n",
    "[What is Multimodal Search: \"LLMs with vision\" change businesses](https://cloud.google.com/blog/products/ai-machine-learning/multimodal-generative-ai-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BE1tELsH-u8N"
   },
   "source": [
    "# Utilities\n",
    "\n",
    "Sometimes it takes tens of minutes to create or deploy Indexes and you would lose connection with the Colab runtime. In that case, instead of creating or deploying new Index again, you can check [the Vector Search Console](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints) and get the existing ones to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wF_pkdpJ-yaq"
   },
   "source": [
    "## Get an existing Index\n",
    "\n",
    "To get an Index object that already exists, replace the following `[your-index-id]` with the index ID and run the cell. You can check the ID on [the Vector Search Console > INDEXES tab](https://console.cloud.google.com/vertex-ai/matching-engine/indexes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEBkZZt_-0jG"
   },
   "outputs": [],
   "source": [
    "my_index_id = \"[your-index-id]\"  # @param {type:\"string\"}\n",
    "my_index = aiplatform.MatchingEngineIndex(my_index_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vlgzkyw-3CI"
   },
   "source": [
    "## Get an existing Index Endpoint\n",
    "\n",
    "To get an Index Endpoint object that already exists, replace the following `[your-index-endpoint-id]` with the Index Endpoint ID and run the cell. You can check the ID on [the Vector Search Console > INDEX ENDPOINTS tab](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0OFnirF-6Rk"
   },
   "outputs": [],
   "source": [
    "my_index_endpoint_id = \"[your-index-endpoint-id]\"  # @param {type:\"string\"}\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(my_index_endpoint_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
